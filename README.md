# Deep learning  

*****

>## 실습예제   
>#### github 블로그 <a href = "https://jiyun1006.github.io/blog/categories/AI/#/">[클릭]</a>

<br>


### **<a href = "https://github.com/jiyun1006/colab_deep/blob/main/SoftMax_MNIST.md">softmax 회귀로 MNIST 데이터 분류</a>**   

<br>
 
### **<a href = "https://github.com/jiyun1006/Deep_first/blob/main/CNN_MNIST.md"/>CNN모델을 이용해서 MNIST 데이터 분류</a>**     


<br>

### **<a href = "https://github.com/jiyun1006/jiyun1006.github.io/blob/master/_posts/2021-02-15-NLP_preprocessing(1).md">Naive Bayes classifier 구현</a>**    


<br>


### **<a href = "https://github.com/jiyun1006/jiyun1006.github.io/blob/master/_posts/2021-02-15-NLP_preprocessing(2).md">Word2Vec - CBOW, Skip-gram 구현</a>**   


<br>

### **<a href ="https://github.com/jiyun1006/jiyun1006.github.io/blob/master/_posts/2021-02-17-Sequence-to-Sequence.md">Sequence to Seuquence 모델 구현</a>**   

<br>

### **<a href = "https://github.com/jiyun1006/jiyun1006.github.io/blob/master/_posts/2021-02-18-Transformer.md"> Transformer - Multi-head-Attention</a>**

